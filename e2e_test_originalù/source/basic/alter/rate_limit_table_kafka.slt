############## Create kafka seed data

statement ok
create table kafka_seed_data (v1 int);

statement ok
insert into kafka_seed_data select * from generate_series(1, 1000);

############## Sink into kafka

statement ok
create sink kafka_sink
from
  kafka_seed_data with (
    properties.bootstrap.server = 'message_queue:29092',
    topic = 'kafka_source',
    type = 'append-only',
    force_append_only='true',
    connector = 'kafka'
);

############## Source from kafka (rate_limit = 0)

statement ok
create table kafka_source (v1 int) with (
  connector = 'kafka',
  topic = 'kafka_source',
  properties.bootstrap.server = 'message_queue:29092',
  scan.startup.mode = 'earliest',
  streaming_rate_limit = 0
) FORMAT PLAIN ENCODE JSON

statement ok
flush;

############## Check data

skipif in-memory
sleep 3s

skipif in-memory
query I
select count(*) from kafka_source;
----
0

############## Can still insert data when rate limit = 0

statement ok
insert into kafka_source values(1);

statement ok
flush;

query I
select count(*) from kafka_source;
----
1

############## Alter source (rate_limit = 0 --> rate_limit = 1000)

skipif in-memory
query I
alter table kafka_source set streaming_rate_limit to 1000;

skipif in-memory
query I
alter table kafka_source set streaming_rate_limit to default;

skipif in-memory
sleep 3s

skipif in-memory
query I
select count(*) > 1 from kafka_source;
----
t

############## Cleanup

statement ok
drop table kafka_source;

statement ok
drop sink kafka_sink;

statement ok
drop table kafka_seed_data;